\chapter{Metody operuj¹ce na poziomie pikseli}
\label{cha:Metody operuj¹ce na poziomie pikseli}
\section{Mixture of Gaussians (MOG)}
\subsection{Wprowadzenie}
T³o sceny zawiera wiele dynamicznych obiektów jak poruszane na wietrze ga³êzie i liœcie drzew czy krzewów. Takie zmiany w tle powoduj¹, ¿e wartoœæ intensywnoœci danego piksela w czasie mog¹ siê bardzo ró¿niæ od siebie. Z tego powodu wykorzystanie pojedynczego przybli¿enia rozk³adu prawdopodobieñstwa przy u¿yciu krzywej Gaussa daje z³e rezultaty. Zamiast tego w opisywanej metodzie u¿yto podejœcia bazuj¹cego na wykorzystaniu kilku rozk³adów Gaussa o ró¿nych parametrach w celu zamodelowania takich zmian\cite{7}.

Standardowe adaptacyjne modele t³a polegaj¹ na tworzeniu aproksymacji t³a, które jest podobne do obecnej statycznej sceny za wyj¹tkiem miejsc w których odby³ siê ruch. Podejœcie takie jest efektywne w sytuacjach gdy obiekty poruszaj¹ siê stale, a t³o jest widoczne znaczn¹ czêœæ czasu, jednak¿e nie sprawdza siê ono dla scen zawieraj¹cych du¿o poruszaj¹cych siê obiektów, a w szczególnoœci, gdy obiekty poruszaj¹ siê powoli. Nie potrafi tak¿e poradziæ sobie z t³ami posiadaj¹cymi rozk³ad dwumodalny, powoli odtwarza t³o jeœli zostanie ono odkryte i ma jeden ustalony próg dla ca³ej sceny. 

W opisywanej metodzie zamiast modelowaæ wartoœci wszystkich pikseli jako wy³¹cznie jeden typ rozk³adu, wartoœci dla ka¿dego piksela modelowane s¹ mieszanka rozk³adów Gaussa. Bazuj¹c na trwa³oœci i wariancji ka¿dego u¿ytego do mieszanki rozk³adu Gaussa okreœlane jest które z nich mog¹ odnosiæ siê do kolorów t³a. Wartoœci pikseli, które nie mieszcz¹ siê w ¿adnym rozk³adzie t³a uznawane s¹ za piksele nale¿¹ce do pierwszego planu. Taki stan pikseli utrzymuje siê do czasu kiedy zaczn¹ wystarczaj¹co dobrze pasowaæ któregoœ z rozk³adów t³a. 

Opisywana metoda dostosowuje siê aby radziæ sobie ze zmianami oœwietlenia, powtarzalnymi ruchami elementów t³a, powolnie poruszaj¹cymi siê elementami pierwszego planu oraz prowadzaniu lub usuwaniu elementów ze sceny. Powolnie poruszaj¹ce siê elementy potrzebuj¹ wiêcej czasu aby wpasowaæ siê w t³o, poniewa¿ ich ma wiêksz¹ wariancjê ni¿ t³o. Powtarzaj¹ce siê zmiany równie¿ s¹ uwzglêdniane, a model rozk³adu t³a jest utrzymywany nawet jeœli jest chwilowo zamieniony przez inny rozk³ad, co prowadzi do szybszego odtworzenia t³a w przypadku usuniêcia obiektów ze sceny.
Metoda ta wykorzystuje dwa podstawowe parametry: 
\begin{lstlisting}
a - sta³a uczenia
T - porcja danych jaka powinna byæ uwzglêdniona w tle
\end{lstlisting}

Zak³adaj¹c, ¿e ka¿dy piksel obrazu bêdzie pochodzi³ z jednej p³aszczyzny przy zmiennym œwietleniu, to do wydzielenia t³a z takiego obrazu wystarczy u¿ycie pojedynczej adaptacyjnej aproksymacji rozk³adem Gaussa dla ka¿dego piksela. Jednak¿e w rzeczywistych warunkach na obrazie wystêpuje wiele powierzchni oraz zmienne oœwietlenie, co sprawia, ¿e potrzebne jest u¿ycie kilku adaptacyjnych rozk³adów Gaussa. W opisywanej metodzie u¿yta jest mieszanka kilku adaptacyjnych rozk³adów Gaussa. Za ka¿dym razem, gdy parametry rozk³adu s¹ aktualizowane, nastêpuje proces oceny dostêpnych rozk³adów w celu okreœlenia tego najbardziej prawdopodobnego. 

\subsection{Opis metody}
\subsubsection{Model mieszanki}

Niech kolejne wartoœci danego piksela w czasie nazywaj¹ siê "pixel process". Zatem "pixel process" jest to seria danego wartoœci piksela. przy czym dla obrazów w skali szaroœci s¹ to wartoœci skalarne, a dla obrazów kolorowych s¹ to wektory. O danym pikselu $\{x_0,y_0\}$ w danej chwili czasu t, mo¿na powiedzieæ, ¿e znana jest jego historia
\begin{equation}
\{X_1,\dots,X_t\}=\{I(x_0,y_0,i):1\le i \le t\}
\end{equation}
gdzie $I$ jest sekwencj¹ ramek.

%Wartoœæ ka¿dego piksela odzwierciedla jasnoœæ odpowiadaj¹cego mu w rzeczywistoœci miejsca w przestrzeni, wiêc jeœli panuj¹ tam statyczne warunki oœwietlenia, to wartoœæ ta jest relatywnie sta³a. W takim przypadku zak³adaj¹c, ¿e w trakcie procesu akwizycji obrazu  powsta³ szum Gaussowski, to mo¿na go opisaæ jedn¹ krzyw¹ Gaussa ze œrodkiem rozk³adu umieszczonym w okolicach œredniej wartoœci piksela. Niestety rzeczywiste sekwencje wideo najczêœciej zawieraj¹ dynamicznie zmieniaj¹ce siê oœwietlenie, zmiany sceny oraz poruszaj¹ce siê obiekty. W przypadku zmiany oœwietlenia w statycznej scenie 


%If  lighting changes occurred in a static scene, it 
%would be necessary for the Gaussian to track those 
%changes.  
%If  a static object was added to the scene 
%and was not incorporated into the background until it 
%had been there longer than the previous object, the 
%corresponding pixels could be considered foreground 
%for arbitrarily long periods. 
%This would lead to accu- 
%mulated errors in the foreground estimation, resulting 
%in poor tracking behavior. These factors suggest that 
%more recent observations may be more important in 
%determining the Gaussian parameter estimates. 
%An additional aspect of variation occurs if moving 
%objects are present in the scene. Even a relatively con- 
%sistently colored moving object is generally expected 
%to produce more variance than a “static” object. Also, 
%in general, there should be more data supporting the 
%background distributions because they are repeated, 
%whereas pixel values for different objects are often not 
%the same color. 
%These are the guiding factors in our choice of model 
%and update procedure.  
%The recent history of each 
%pixel, {XI,  ..., Xt}, is modeled by a mixture of K Gaus- 
%sian distributions.  The probability of observing the 
%current pixel value is 
%K 
Niedawna historia dla ka¿dego piksela modelowana jest mieszanin¹ K rozk³adów Gaussa. Prawdopodobieñstwo zaobserwowania obecnego piksela okreœla siê wzorem

\begin{equation}
P(X_t)=\sum_{i=1}^{K} \omega_{i,t} * \eta(X_t, \mu_{i,t} , \Sigma_{i,t})
\end{equation}

gdzie K jest iloœci¹ rozk³adów,  $\omega_{i,t}$ jest oszacowan¹ wag¹ $i$-tego rozk³adu w mieszance w chwili $t$, $\mu_{i,t}$ jest œredni¹ wartoœci¹  $i$-tego rozk³adu w mieszance w chwili $t$, $\Sigma_{i,t}$ jest macierz¹ kowariancji $i$-tego rozk³adu w mieszance w chwili $t$,$\eta$ jest funkcj¹ gêstoœci prawdopodobieñstwa Gaussa

\begin{equation}
\eta(X_t,\mu,\Sigma)=\frac{1}{(2\pi)^\frac{n}{2} |\Sigma|^\frac{1}{2}}e^{-\frac{1}{2}(X_t-\mu_t)^T \Sigma^{-1} (W_t -\mu_t)}
\end{equation}

gdzie K okreœlane jest przez dostêpn¹ pamiêæ oraz moc obliczeniow¹ jednostki na której wykonywany jest algorytm. Najczêœciej spotykan¹ wartoœci¹ jest od 3 do 5. W celu zmniejszenia iloœci obliczeñ przyjmuje siê, ¿e macierz kowariancji ma postaæ:

\begin{equation}
\Sigma_{k,t}=\sigma^2_kI
\end{equation}

Takie rozwi¹zanie zak³ada, ¿e wartoœci dla poszczególnych kolorów sk³adowych ka¿dego piksela maj¹ tak¹ sam¹ wariancjê. Takie za³o¿enie jest b³êdne, lecz pozwala omin¹æ odwracanie macierzy, co jest zadaniem bardzo kosztownym, za cenê mniejszej precyzji. 

Zatem rozk³ad ostatnio obserwowanych wartoœci dla ka¿dego piksela w obrazie opisany jest mieszank¹ rozk³adów Gaussa. Nowa wartoœæ piksela bêdzie na ogó³ reprezentowana przez jeden z g³ównych sk³adników mieszanki. 

%If  the pixel process could be considered a sta- 
%tionary process, a standard method for maximizing 
%the likelihood  of  the observed data is  expectation 
%maxzmizatzon[ 11.  Unfortunately, each pixel process 
%varies over time as the state of the world changes, 
%so we use an approximate method which essentially 
%treats each new observation as a sample set of size 1 
%and uses standard learning rules to integrate the new 
%data. 
%Because there is a mixture model for every pixel in 
%the image, implementing an exact EM algorithm on 
%a window of recent data would be costly. 

Do obliczenia wartoœci nowego piksela u¿yta zosta³a metoda on-line K-means approximation (t³umaczenie?). Ka¿da wartoœæ piksela jest sprawdzana pod k¹tem dopasowania do jednego z K rozk³adów. Warunkiem przynale¿noœci jest wartoœæ w zakresie do 2,5 odchylenia standardowego z danego rozk³adu. Zmiana opisanego wczeœniej progu ma niewielki wp³yw na wydajnoœæ algorytmu. Opisany sposób wyboru odpowiednich pikseli jest bardzo u¿yteczny dla obszarów z ró¿nym oœwietleniem, poniewa¿ obiekty znajduj¹ce siê w zacienionych obszarach maj¹ mniejszy szum ni¿ obiekty znajduj¹ce siê w jaœniejszych regionach.

W przypadku gdy ¿aden rozk³ad nie zosta³ dopasowany do danego piksela, to rozk³ad z najmniejsz¹ wag¹ jest zastêpowany nowym z wartoœci¹ piksela jako now¹ wartoœci¹ oczekiwan¹, du¿¹ wariancj¹ i nisk¹ wag¹.

Wczeœniejsze wagi K rozk³adów w czasie t s¹ aktualizowane wg wzoru 

\begin{equation}
\omega_{k,t}=(1-\alpha)\omega_{k,t-1}+\alpha(M_{k,t})
\end{equation}
gdzie $\alpha$ to tempo uczenia, a $M_{k,t}$ jest 1 dla dopasowanego rozk³adu i 0 dla pozosta³ych rozk³adów. Po dokonaniu aproksymacji wagi s¹ normalizowane. $\frac{1}{\alpha}$ oznacza sta³¹ czasow¹ okreœlaj¹c¹ prêdkoœæ z jak¹ parametry rozk³adów siê zmieniaj¹.

Dla rozk³adów niedopasowanych do danego piksela wartoœci $\mu$ i $\sigma$ pozostaj¹ niezmienione. Dla rozk³adów, które zosta³y dopasowane wartoœci $\mu$ i $\sigma$ obliczane s¹ nastêpuj¹co:

\begin{equation}
\mu_t=(1-\rho)\mu_{t-1}+\rho X_t
\end{equation}

\begin{equation}
\sigma^2_t=(1-\rho)\sigma^2_{t-1}+\rho(X_t-\mu_t)^T(X_t-\mu_t)
\end{equation}
przy czym

\begin{equation}
\rho = \alpha\eta(X_t|\mu_k,\sigma_k)
\end{equation}

Jedn¹ z najwiêkszych zalet opisanego rozwi¹zania jest fakt, ¿e kiedy jakiœ obiekt zostanie dodany do t³a, to nie niszczy on istniej¹cego modelu t³a. Oryginalny kolor t³a zostaje zachowany w mieszance do czasu a¿ stanie siê najmniej prawdopodobnym kolorem oraz zostanie zaobserwowany nowy kolor. Zatem jeœli obiekt pozostanie nieruchomy wystarczaj¹co d³ugo aby staæ siê czêœci¹ t³a, a nastêpnie siê poruszy, to rozk³ad opisuj¹cy poprzednie t³o ci¹gle istnieje w tymi samymi $\mu$ i $\sigma^2$, ale mniejszym $\omega$ przez co mo¿e zostaæ szybko ponownie do³¹czony do modelu t³a.

\subsubsection{Estymacja modelu t³a}


Podczas gdy parametry modelu mieszanki dla ka¿dego piksela zmieniaj¹ siê, nale¿y okreœliæ które rozk³ady z mieszanki daj¹ najwiêksze prawdopodobieñstwo bycia wygenerowanymi przez procesy t³a. Z heurystycznego punktu widzenia najbardziej interesuj¹ce s¹ rozk³ady, które daj¹ najlepsze dopasowanie i najmniejsz¹ wariancjê



%To understand this choice, consider the accumu- 
%lation of supporting evidence and the relatively low 
%variance for the “background” distributions when a 
%static, persistent object is visible. In contrast, when 
%a new object occludes the background object, it will 
%not, in general, match one of the existing distributions 
%which will result in either the creation of a new dis- 
%tribution or the increase in the variance of an existing 
%distribution. Also, the variance of the moving object 
%is expected to remain larger than a background pixel 
%until the moving object stops. To model this, we need 
%a method for deciding what portion of the mixture 
%model best represents background processes. 

W celu wybrania odpowiednich rozk³adów nale¿y uszeregowaæ je wed³ug wartoœci $\omega$/$\sigma$. Wartoœæ ta zwiêksza siê zarówno przy zwiêkszeniu dopasowania, jak i przy zmniejszeniu wariancji. W praktyce tak uszeregowana lista daje zbiór rozk³adów, gdzie najbardziej prawdopodobni kandydaci znajduj¹ siê na pocz¹tku, a najmniej prawdopodobni na koñcu.
Pierwsze rozk³ady wybrane jako model t³a wybiera siê za pomoc¹ wzoru 

\begin{equation}
B = argmin_b\left(\sum_{k=1}^{b}\omega_k>T\right)
\end{equation}
gdzie T jest miar¹ minimalnej iloœci danych jaka powinna byæ prana pod uwagê. Rozwi¹zanie takie bierze pod uwagê najlepiej dostosowany rozk³ad dot¹d, a¿ pewna porcja T danych jest rozwa¿ona. Jeœli T jest jest wartoœci¹ ma³¹, to tedy model t³a zazwyczaj jest unimodalny. Jeœli T jest wartoœci¹ wiêksz¹, multimodalny rozk³ad wywo³any powtarzalnymi ruchami w tle mo¿e skutkowaæ uwzglêdnieniem w modelu t³a wiêcej ni¿ jednego koloru. Skutkuje to efektem przezroczystoœci, który pozwala modelowi przyjmowaæ dwa lub wiêcej oddzielnych kolorów. 

%This takes the “best” distributions until a certain por- 
%tion, T, of the recent data has been accounted for. If 
%a small value for T is chosen, the background model 
%is usually unimodal. If this is the case, using only the 
%most probable distribution will save processing. 
%If  T is higher, a multi-modal distribution caused 
%by a repetitive background motion  
%could result in more than one color being included in 
%the background model. This results in a transparency 
%effect which allows the background to accept two or 
%more separate colors.