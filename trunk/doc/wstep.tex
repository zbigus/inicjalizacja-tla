\chapter{Wstêp}
\label{wstep}

W dzisiejszych czasach systemy wizyjne znajduj¹ coraz wiêcej zastosowañ w~¿yciu codziennym. Wraz ze wzrostem mocy obliczeniowej wspó³czesnych komputerów oraz coraz ni¿szych cen kamer i~sprzêtu wizyjnego mo¿na zaobserwowaæ dynamiczny rozwój tej dziedziny informatyki. S¹ one u¿ywane miêdzy innymi w~systemach inteligentnego obszarowego sterowania ruchem, monitoringu przestrzeni miejskiej oraz w~bardziej zaawansowanych rozwi¹zaniach CCTV, jak na przyk³ad systemy œledzenia potencjalnych zagro¿eñ na lotniskach lub w~miejscach publicznych. We wszystkich wy¿ej wymienionych zastosowaniach kluczow¹ kwesti¹ jest oddzielenie pierwszego planu od t³a. Odseparowanie dynamicznych elementów obrazu od statycznej scenerii jest podstaw¹ dzia³ania wszystkich algorytmy œledz¹cych.

Pomimo ci¹g³ego rozwoju algorytmów stosowanych do inicjalizacji modelu t³a nadal istniej¹ sytuacje w~których algorytmy te nie s¹ w~stanie wygenerowaæ poprawnych rezultatów. Najwiêksze problemy sprawiaj¹ zmienne warunki oœwietlenia oraz drobne ruchy obiektów t³a (np. liœcie na wietrze). Kolejnym niepo¿¹danym zjawiskiem jest wtapianie siê obiektów z~pierwszego planu w~t³o, gdy pozostaj¹ one przez d³ugi czas nieruchome. 
Nieustannie trwaj¹ prace nad stworzeniem algorytmów eliminuj¹cych lub minimalizuj¹cych skutki wy¿ej wymienionych zjawisk. Próby te zosta³y opisane miêdzy innymi w~\cite{Baltieri2010} oraz \cite{Reddy2009}.
Metody te zaliczaj¹ siê do klasy metod przestrzennych (blokowych), a~ich zaimplementowanie i~porównanie bêdzie stanowiæ jeden z~celów niniejszej pracy. Nastêpnie zostan¹ one skonfrontowane z~metodami operuj¹cymi na poziomie pikseli - opisanymi w~\cite{7} oraz \cite{Wang2006}.

